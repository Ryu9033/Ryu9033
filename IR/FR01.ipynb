{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWMqUXie7dgO"
   },
   "source": [
    "## 画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ITbic4_DPiI"
   },
   "source": [
    "データ前処理、データセットの読み込み・加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_4c-W6oG-XE"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation,Dropout,Flatten,Dense,GlobalAveragePooling2D\n",
    "from keras.utils  import np_utils\n",
    "\n",
    "\n",
    "# クラスラベル\n",
    "labels = [\"grape\",\"apple\",\"orange\"]\n",
    "# ディレクトリ\n",
    "dataset_dir = \"/IR/data/dataset.npy\" # 前処理済みデータ\n",
    "model_dir   = \"/IR/data/cnn_h5\"      # 学習済みモデル\n",
    "# リサイズ設定\n",
    "resize_settings = (50,50)\n",
    "\n",
    "# 画像データ\n",
    "X_train = [] # 学習\n",
    "y_train = [] # 学習ラベル\n",
    "X_test  = [] # テスト\n",
    "y_test  = [] # テストラベル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oY0BuQtG7Okx",
    "outputId": "bab8a8f5-84c1-4a8e-97d4-7296a6788afc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "for class_num, label in enumerate(labels):\n",
    "    \n",
    "    # 写真のディレクトリ\n",
    "    photos_dir = \"/IR/data/\" + label\n",
    "    \n",
    "    # 画像データを取得\n",
    "    files = glob.glob(photos_dir + \"/*.jpg\")\n",
    "   \n",
    "    #写真を順番に取得\n",
    "    for i,file in enumerate(files):\n",
    "        \n",
    "        # 画像を1つ読込\n",
    "        image = Image.open(file)\n",
    "        \n",
    "        # 画像をRGBの3色に変換\n",
    "        image = image.convert(\"RGB\")\n",
    "        \n",
    "        # 画像のサイズを揃える\n",
    "        image = image.resize(resize_settings)\n",
    "        \n",
    "        # 画像を数字の配列変換\n",
    "        data  = np.asarray(image) \n",
    "\n",
    "        # テストデータ追加\n",
    "        if i == rand - 1:\n",
    "            X_test.append(data)\n",
    "            y_test.append(class_num)\n",
    "        \n",
    "        # 学習データかさ増し\n",
    "        else:            \n",
    "            # -25度から20度まで5度刻みで回転したデータを追加\n",
    "            for angle in range(-25,20,5):\n",
    "                # 回転\n",
    "                img_r = image.rotate(angle)\n",
    "                # 画像 → 数字の配列変換\n",
    "                data  = np.asarray(img_r)\n",
    "                # 追加\n",
    "                X_train.append(data)\n",
    "                y_train.append(class_num)\n",
    "                # 画像左右反転\n",
    "                img_trans = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                data      = np.asarray(img_trans)\n",
    "                # 追加\n",
    "                X_train.append(data)\n",
    "                y_train.append(class_num)        \n",
    "\n",
    "\n",
    "# X,YがリストなのでTensorflowが扱いやすいようnumpyの配列に変換\n",
    "X_train = np.array(X_train)\n",
    "X_test  = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test  = np.array(y_test)\n",
    "\n",
    "\n",
    "# 前処理済みデータを保存\n",
    "dataset = (X_train,X_test,y_train,y_test)\n",
    "np.save(dataset_dir,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u222HwuMKGBW"
   },
   "source": [
    "#### モデル学習・評価 | CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viOBwxFaKAZy"
   },
   "outputs": [],
   "source": [
    "# メインの関数定義\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ①データの前処理(エンコーディング)\n",
    "    \"\"\"\n",
    "    # 保存したnumpyデータ読み込み\n",
    "    X_train,X_test,y_train,y_test = np.load(dataset_dir, allow_pickle=True)\n",
    "    \n",
    "    # 0~255の整数範囲になっているため、0~1間に数値が収まるよう正規化\n",
    "    X_train = X_train.astype(\"float\") / X_train.max()\n",
    "    X_test  = X_test.astype(\"float\") /  X_train.max()\n",
    "    \n",
    "    # クラスラベルの正解値は1、他は0になるようワンホット表現を適用\n",
    "    y_train = np_utils.to_categorical(y_train,len(labels))\n",
    "    y_test  = np_utils.to_categorical(y_test,len(labels))\n",
    "    \"\"\"\n",
    "    ②モデル学習&評価\n",
    "    \"\"\"\n",
    "    #モデル学習\n",
    "    model = model_train(X_train,y_train)\n",
    "    \n",
    "    #モデル評価\n",
    "    evaluate(model,X_test, y_test)\n",
    "    \n",
    "  \n",
    "    \n",
    "#モデル学習関数\n",
    "def model_train(X_train,y_train):\n",
    "    \n",
    "    #インスタンス\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1層目 (畳み込み）\n",
    "    model.add(Conv2D(32,(3,3),padding=\"same\", input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 2層目 (Max Pooling)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))                     \n",
    "    model.add(Dropout(0.3))         \n",
    "\n",
    "    # 3層目 (畳み込み)\n",
    "    model.add(Conv2D(64,(3,3),padding=\"same\"))                   \n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 4層目 (Max Pooling)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Global Average Pooling\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    # 5層目 (全結合層)\n",
    "    model.add(Dense(512))                                       \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 出力層(softmaxで0〜1の確率を返す)\n",
    "    model.add(Dense(3)) \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # 最適化アルゴリズム Adam\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "\n",
    "    # 損失関数\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\"]\n",
    "                 )\n",
    "                  \n",
    "    # モデル学習\n",
    "    model.fit(X_train,y_train,batch_size=10,epochs=150)\n",
    "    \n",
    "    # モデルの結果を保存\n",
    "    model.save(model_dir)\n",
    "    return model\n",
    "    \n",
    "\n",
    "# 評価用関数\n",
    "def evaluate(model,X_test,y_test):\n",
    "    # モデル評価\n",
    "    scores = model.evaluate(X_test,y_test,verbose=1)\n",
    "    print(\"Test Loss: \", scores[0])\n",
    "    print(\"test Accuracy: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "xf9PyxM3_V6y",
    "outputId": "83c5feff-f776-4173-f053-d9df796b08e1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a8b4be708a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# モデル学習実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0de24bac70c6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 保存したnumpyデータ読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 0~255の整数範囲になっているため、0~1間に数値が収まるよう正規化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/dataset.npy'"
     ]
    }
   ],
   "source": [
    "# モデル学習実行\n",
    "model = main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
